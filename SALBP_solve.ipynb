{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import subprocess\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jot240/DADA/DADA\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jot240/DADA/DADA/SALBP_solve.py\", line 2, in <module>\n",
      "    import networkx as nx\n",
      "ModuleNotFoundError: No module named 'networkx'\n"
     ]
    }
   ],
   "source": [
    "! python SALBP_solve.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_alb(alb_file_name):\n",
    "    \"\"\"Reads assembly line balancing instance .alb file, returns dictionary with the information\"\"\"\n",
    "    parse_dict = {}\n",
    "    alb_file = open(alb_file_name).read()\n",
    "    # Get number of tasks\n",
    "    num_tasks = re.search(\"<number of tasks>\\n(\\\\d*)\", alb_file)\n",
    "    parse_dict[\"num_tasks\"] = int(num_tasks.group(1))\n",
    "\n",
    "    # Get cycle time\n",
    "    cycle_time = re.search(\"<cycle time>\\n(\\\\d*)\", alb_file)\n",
    "    parse_dict[\"cycle_time\"] = int(cycle_time.group(1))\n",
    "\n",
    "    # Order Strength\n",
    "    order_strength = re.search(\"<order strength>\\n(\\\\d*,\\\\d*)\", alb_file)\n",
    "    \n",
    "    if order_strength:\n",
    "        parse_dict[\"original_order_strength\"] = float(order_strength.group(1).replace(\",\", \".\"))\n",
    "    else:\n",
    "        order_strength = re.search(\"<order strength>\\n(\\\\d*.\\\\d*)\", alb_file)\n",
    "        parse_dict[\"original_order_strength\"] = float(order_strength.group(1))\n",
    "\n",
    "    # Task_times\n",
    "    task_times = re.search(\"<task times>(.|\\n)+?<\", alb_file)\n",
    "\n",
    "    # Get lines in this regex ignoring the first and last 2\n",
    "    task_times = task_times.group(0).split(\"\\n\")[1:-2]\n",
    "    task_times = {task.split()[0]: int(task.split()[1]) for task in task_times}\n",
    "    parse_dict[\"task_times\"] = task_times\n",
    "\n",
    "    # Precedence relations\n",
    "    precedence_relations = re.search(\"<precedence relations>(.|\\n)+?<\", alb_file)\n",
    "    precedence_relations = precedence_relations.group(0).split(\"\\n\")[1:-2]\n",
    "    precedence_relations = [task.split(\",\") for task in precedence_relations]\n",
    "    parse_dict[\"precedence_relations\"] = precedence_relations\n",
    "    return parse_dict\n",
    "\n",
    "def write_to_alb(salbp_dict, alb_file_name):\n",
    "    \"\"\"Writes the SALBP dictionary to an .alb file\"\"\"\n",
    "    #Format of alb:\n",
    "    # <number of tasks>\n",
    "    # no_tasks\n",
    "    # <cycle time>\n",
    "    # cycle_time\n",
    "    #<task times>\n",
    "    #task_id task_time\n",
    "    #<precedence relations>\n",
    "    #task_id,task_id\n",
    "\n",
    "\n",
    "    # Write number of tasks\n",
    "    alb = \"<number of tasks>\\n\"\n",
    "    alb += str(salbp_dict[\"num_tasks\"]) + \"\\n\"\n",
    "    # Write cycle time\n",
    "    alb += \"<cycle time>\\n\"\n",
    "    alb += str(salbp_dict[\"cycle_time\"]) + \"\\n\"\n",
    "    # Write task times\n",
    "    alb += \"<task times>\\n\"\n",
    "    for task_id, task_time in salbp_dict[\"task_times\"].items():\n",
    "        alb += task_id + \" \" + str(task_time) + \"\\n\"\n",
    "    # Write precedence relations\n",
    "    alb += \"<precedence relations>\\n\"\n",
    "    for relation in salbp_dict[\"precedence_relations\"]:\n",
    "        alb += relation[0] + \",\" + relation[1] + \"\\n\"\n",
    "    #ends the file\n",
    "    alb += \"<end>\"\n",
    "    with open(alb_file_name, \"w\") as alb_file:\n",
    "        alb_file.write(alb)\n",
    "    \n",
    "\n",
    "\n",
    "SALBP_dict = parse_alb(\"../../MALBPW/MMABPW/SALBP_benchmark/small data set_n=20/instance_n=20_1.alb\")\n",
    "write_to_alb(SALBP_dict, \"test.alb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_tasks': 20,\n",
       " 'cycle_time': 1000,\n",
       " 'original_order_strength': 0.268,\n",
       " 'task_times': {'1': 142,\n",
       "  '2': 34,\n",
       "  '3': 140,\n",
       "  '4': 214,\n",
       "  '5': 121,\n",
       "  '6': 279,\n",
       "  '7': 50,\n",
       "  '8': 282,\n",
       "  '9': 129,\n",
       "  '10': 175,\n",
       "  '11': 97,\n",
       "  '12': 132,\n",
       "  '13': 107,\n",
       "  '14': 132,\n",
       "  '15': 69,\n",
       "  '16': 169,\n",
       "  '17': 73,\n",
       "  '18': 231,\n",
       "  '19': 120,\n",
       "  '20': 186},\n",
       " 'precedence_relations': [['1', '6'],\n",
       "  ['2', '7'],\n",
       "  ['4', '8'],\n",
       "  ['5', '9'],\n",
       "  ['6', '10'],\n",
       "  ['7', '11'],\n",
       "  ['8', '12'],\n",
       "  ['10', '13'],\n",
       "  ['11', '13'],\n",
       "  ['12', '14'],\n",
       "  ['12', '15'],\n",
       "  ['13', '16'],\n",
       "  ['13', '17'],\n",
       "  ['13', '18'],\n",
       "  ['14', '20'],\n",
       "  ['15', '19']]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SALBP_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.alb\n",
      "n=20\n",
      "cycle time=1000\n",
      "t1=142 t2=34 t3=140 t4=214 t5=121 t6=279 t7=50 t8=282 t9=129 t10=175 t11=97 t12=132 t13=107 t14=132 t15=69 t16=169 t17=73 t18=231 t19=120 t20=186 \n",
      "running in reverse 2880000 2720000\n",
      "MHH upper bound: 3 (0.00s)\n",
      "First lower bound: 3\n",
      "Optimality proved by LB1\n",
      "Solution with 3 stations\n",
      " 1\t1\n",
      "2\t1\n",
      "3\t3\n",
      "4\t2\n",
      "5\t3\n",
      "6\t1\n",
      "7\t1\n",
      "8\t2\n",
      "9\t3\n",
      "10\t1\n",
      "11\t1\n",
      "12\t2\n",
      "13\t1\n",
      "14\t2\n",
      "15\t2\n",
      "16\t2\n",
      "17\t3\n",
      "18\t3\n",
      "19\t3\n",
      "20\t3\n",
      "test test test.sol\n",
      "   verified_optimality = 1; value = 3; cpu = 0.00\n",
      "Hoffman cpu =   0.00  best_first_bbr cpu =   0.00  bfs_bbr cpu =   0.00 find_insert_cpu =   0.00  bin_cpu =   0.00  cpu =   0.00\n"
     ]
    }
   ],
   "source": [
    "! ../BBR-for-SALBP1/SALB/SALB/salb   \"test.alb\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance name instance_n=50_ 1\n",
      "instance name instance_n=50_ 2\n",
      "instance name instance_n=50_ 3\n",
      "instance name instance_n=50_ 4\n",
      "instance name instance_n=50_ 5\n",
      "instance name instance_n=50_ 6\n",
      "instance name instance_n=50_ 7\n",
      "instance name instance_n=50_ 8\n",
      "instance name instance_n=50_ 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def random_task_time_change(SALBP_dict, multiplier = 1.5):\n",
    "    \"\"\"Increases a random task time by 1\"\"\"\n",
    "    import random\n",
    "    task_id = random.choice(list(SALBP_dict[\"task_times\"].keys()))\n",
    "    SALBP_dict[\"task_times\"][task_id] *= multiplier\n",
    "    return SALBP_dict\n",
    "\n",
    "def task_time_change(SALBP_dict, task_id, multiplier = 1.5, debug = False):\n",
    "    \"\"\"Increases a random task time by 1\"\"\"\n",
    "    if debug:\n",
    "        print(\"Changing task\", task_id, \"time by\", multiplier)\n",
    "    SALBP_dict[\"task_times\"][task_id] *= multiplier\n",
    "    return SALBP_dict\n",
    "\n",
    "def precedence_removal(SALBP_dict, edge_index):\n",
    "    \"\"\"Removes a precedence relation\"\"\"\n",
    "    SALBP_dict[\"precedence_relations\"].pop(edge_index)\n",
    "    return SALBP_dict\n",
    "    \n",
    "\n",
    "def parse_bb_salb1_out(text):\n",
    "    '''gets the number of stations, optimal flag and cpu time from the output of the salb1 program'''\n",
    "    output = text.stdout.decode(\"utf-8\")\n",
    "    # Regular expression to capture the required values\n",
    "    match = re.search(r\"verified_optimality\\s*=\\s*(\\d+);\\s*value\\s*=\\s*(\\d+);\\s*cpu\\s*=\\s*([\\d.]+)\", output)\n",
    "\n",
    "    if match:\n",
    "        verified_optimality = int(match.group(1))\n",
    "        value = int(match.group(2))\n",
    "        cpu = float(match.group(3))\n",
    "\n",
    "    else:\n",
    "        print(\"Pattern not found.\")\n",
    "    return value, verified_optimality, cpu\n",
    "\n",
    "\n",
    "def save_backup(backup_name, result):\n",
    "    intermediate = pd.DataFrame([result])\n",
    "    my_file = Path(backup_name)\n",
    "    if my_file.is_file():\n",
    "        intermediate.to_csv(backup_name, mode='a', header=False)\n",
    "    else:\n",
    "        intermediate.to_csv(backup_name)\n",
    "    \n",
    "def generate_results(fp = \"/Users/letshopethisworks2/Documents/phd_paper_material/MMABPWW/SALBP_benchmark/small data set_n=20/\" ,  ex_fp = \"../BBR-for-SALBP1/SALB/SALB/salb\", instance_name = \"instance_n=20_\", ext = \".alb\", start=1, stop = 300, backup_name = f\"SALBP_edge_solutions.csv\"):\n",
    "    results = []\n",
    "    for i in range(start,stop):\n",
    "        SALBP_dict_orig = parse_alb(f\"{fp}{instance_name}{i}{ext}\")\n",
    "        bin_dict = deepcopy(SALBP_dict_orig)\n",
    "        print(\"instance name\", instance_name, i)\n",
    "        for j in range(len(SALBP_dict_orig[\"precedence_relations\"])):\n",
    "            SALBP_dict = deepcopy(SALBP_dict_orig)\n",
    "            SALBP_dict =precedence_removal(SALBP_dict, j)\n",
    "            write_to_alb(SALBP_dict, \"test.alb\")\n",
    "            output = subprocess.run([ex_fp, \"test.alb\"], stdout=subprocess.PIPE)\n",
    "            no_stations, optimal, cpu = parse_bb_salb1_out(output)\n",
    "            result = {\"instance:\": f\"instance_n=20_{i}\", \"precedence_relation\": j, \"no_stations\": no_stations, \"optimal\": optimal, \"cpu\": cpu}\n",
    "            save_backup(backup_name, result)\n",
    "            results.append(result)\n",
    "\n",
    "        #calculates bin packing lower bound\n",
    "        bin_dict['precedence_relations'] = []\n",
    "        write_to_alb(bin_dict, \"test.alb\")\n",
    "        output = subprocess.run([ex_fp, \"test.alb\"], stdout=subprocess.PIPE)\n",
    "        no_stations, optimal, cpu = parse_bb_salb1_out(output)\n",
    "        result = {\"instance:\": f\"instance_n=20_{i}\", \"precedence_relation\": \"None\", \"no_stations\": no_stations, \"optimal\": optimal, \"cpu\": cpu}\n",
    "        save_backup(backup_name, result)\n",
    "            \n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "#reads the results csv\n",
    "#results_df = pd.read_csv(\"task_20_bin_lb.csv\")\n",
    "#results_df = pd.DataFrame(results)\n",
    "#saves the results df to a csv file\n",
    "#results_df.to_csv(\"tasks20_test.csv\")\n",
    "results = generate_results(fp = \"../../MALBPW/MMABPW/SALBP_benchmark/medium data set_n=50/\", instance_name = \"instance_n=50_\", start=1, stop = 10)\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"tasks50_test_1_50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df.to_csv(\"task_20_bin_lb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_df = results_df[results_df[\"precedence_relation\"].isna() == True].copy()\n",
    "#removes the rows with None precedence relations\n",
    "results_df = results_df[results_df['precedence_relation'].isna() == False]\n",
    "\n",
    "lb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets the min and max number of stations for each instance\n",
    "min_and_max = results_df.groupby(\"instance:\")[\"no_stations\"].agg([\"min\", \"max\"])\n",
    "min_and_max.reset_index(inplace = True)\n",
    "#adds in lb values\n",
    "lb_df['bin_lb'] = lb_df['no_stations']\n",
    "min_and_max = pd.merge(min_and_max, lb_df[[\"instance:\", \"bin_lb\"]], on = \"instance:\")\n",
    "min_and_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts the number of times min does not equal max\n",
    "min_and_max[\"min_not_equal_max\"] = min_and_max[\"min\"] != min_and_max[\"max\"]\n",
    "min_and_max[\"min_not_equal_max\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts the number of time the bin_lb is less than the min\n",
    "min_and_max[\"bin_lb_less_than_min\"] = min_and_max[\"bin_lb\"] < min_and_max[\"min\"]\n",
    "min_and_max[\"bin_lb_less_than_min\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts the number of time the bin_lb is less than the max\n",
    "min_and_max[\"bin_lb_less_than_max\"] = min_and_max[\"bin_lb\"] < min_and_max[\"max\"]\n",
    "print(\"bin lb dif\", min_and_max[\"bin_lb_less_than_max\"].sum())\n",
    "#filters for the instances where the bin_lb is les than the max\n",
    "min_and_max[min_and_max[\"bin_lb_less_than_max\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints the instances where min does not equal max\n",
    "interesting_instances = min_and_max[min_and_max[\"min_not_equal_max\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_20_101 = results_df[results_df[\"instance:\"] == \"instance_n=20_101\"]\n",
    "inst_20_101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def plot_salbp_graph(SALBP_dict):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(SALBP_dict[\"task_times\"].keys())\n",
    "    G.add_edges_from(SALBP_dict[\"precedence_relations\"])\n",
    "    #prints the edges\n",
    "    print(\"from dict\", SALBP_dict[\"precedence_relations\"])\n",
    "    #prints the edges from the graph\n",
    "    print(\"from graph\", G.edges())\n",
    "    nx.draw(G, with_labels = True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_salbp_edge_removal_graph(SALBP_dict, instance_name, res_df):\n",
    "    '''Colors the edges by the number of stations in res_df'''\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(SALBP_dict[\"task_times\"].keys())\n",
    "    G.add_edges_from(SALBP_dict[\"precedence_relations\"])\n",
    "    edge_colors = []\n",
    "    for edge in G.edges():\n",
    "        edge_index = SALBP_dict[\"precedence_relations\"].index(list(edge))\n",
    "        no_stations = res_df[(res_df[\"instance:\"] == instance_name) & (res_df[\"precedence_relation\"] == edge_index)][\"no_stations\"].values[0]\n",
    "        edge_colors.append(no_stations)\n",
    "    #saves edge colors as graph attribute\n",
    "    nx.set_edge_attributes(G, dict(zip(G.edges(), edge_colors)), \"value\")\n",
    "    pos = nx.nx_pydot.graphviz_layout(G, prog = \"dot\")\n",
    "   # Define colormap\n",
    "    unique_values = list(set(edge_colors))\n",
    "    print(unique_values)\n",
    "    color_map = cm.get_cmap('viridis', len(unique_values))\n",
    "    print(\"color map\", color_map)\n",
    "    cmap = mcolors.ListedColormap([color_map(val) for val in unique_values])\n",
    "\n",
    "    # Draw graph\n",
    "    #creates ax\n",
    "    fig, ax = plt.subplots()\n",
    "    edges = nx.draw_networkx_edges(G, pos, edge_color=edge_colors, edge_cmap=cmap, edge_vmin=min(edge_colors), edge_vmax=max(edge_colors), ax=ax)\n",
    "    nx.draw_networkx_nodes(G, pos, ax=ax)\n",
    "    nx.draw_networkx_labels(G, pos, ax=ax)\n",
    "\n",
    "    # Add colorbar\n",
    "    handles = [plt.Line2D([0], [0], marker='o', color = color_map(val), label=val, markersize=10) for val in unique_values]\n",
    "    plt.legend(handles=handles, loc=\"best\")\n",
    "\n",
    "    plt.show()\n",
    "    return G\n",
    "\n",
    "\n",
    "def draw_graph_with_discrete_legend(SALBP_dict, res_df, instance_name,  ax=None):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(SALBP_dict[\"task_times\"].keys())\n",
    "    G.add_edges_from(SALBP_dict[\"precedence_relations\"])\n",
    "\n",
    "    edge_colors = []\n",
    "    edge_values = []  # Store unique edge values for legend\n",
    "\n",
    "    for edge in G.edges():\n",
    "        edge_index = SALBP_dict[\"precedence_relations\"].index(list(edge))\n",
    "        no_stations = res_df[(res_df[\"instance:\"] == instance_name) & \n",
    "                             (res_df[\"precedence_relation\"] == edge_index)][\"no_stations\"].values[0]\n",
    "        edge_colors.append(no_stations)\n",
    "        if no_stations not in edge_values:\n",
    "            edge_values.append(no_stations)\n",
    "\n",
    "    # Save edge colors as graph attribute\n",
    "    nx.set_edge_attributes(G, dict(zip(G.edges(), edge_colors)), \"value\")\n",
    "\n",
    "    # Graph layout\n",
    "    pos = nx.nx_pydot.graphviz_layout(G, prog=\"dot\")\n",
    "\n",
    "    # Define discrete colormap\n",
    "    unique_values = sorted(edge_values)\n",
    "    num_colors = len(unique_values)\n",
    "    cmap = plt.cm.get_cmap(\"Set1\", num_colors)  # Use a qualitative colormap\n",
    "    color_map = {val: cmap(i) for i, val in enumerate(unique_values)}  # Assign colors to unique values\n",
    "\n",
    "    # Assign discrete colors to edges\n",
    "    edge_color_list = [color_map[val] for val in edge_colors]\n",
    "\n",
    "    # Draw graph\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    edges = nx.draw_networkx_edges(G, pos, edge_color=edge_color_list, ax=ax)\n",
    "    nx.draw_networkx_nodes(G, pos, ax=ax)\n",
    "    nx.draw_networkx_labels(G, pos, ax=ax)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    # Create legend\n",
    "    handles = [plt.Line2D([0], [0], color=color_map[val], lw=2, label=f\"No. of Stations: {val}\") for val in unique_values]\n",
    "    #ax.legend(handles=handles, loc=\"best\")\n",
    "\n",
    "\n",
    "    return G\n",
    "\n",
    "i = 97\n",
    "\n",
    "test_salb = parse_alb(f\"/Users/letshopethisworks2/Documents/phd_paper_material/MMABPWW/SALBP_benchmark/small data set_n=20/instance_n=20_{i}.alb\")\n",
    "#test_g = plot_salbp_edge_removal_graph(test_salb, f\"instance_n=20_{i}\", results_df)\n",
    "test_g = draw_graph_with_discrete_legend(test_salb, results_df, f\"instance_n=20_{i}\")\n",
    "#saves graph to a gephi readable file\n",
    "nx.write_gexf(test_g, \"test_salb.gexf\")\n",
    "#plot_salbp_graph(test_salb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_instances['instance:'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a plot of the 27 graphs of interest\n",
    "fig, axs = plt.subplots(3, 9, figsize=(20, 20))\n",
    "axs = axs.ravel()\n",
    "for idx, i in enumerate(interesting_instances['instance:'].values):\n",
    "    test_salb = parse_alb(f\"/Users/letshopethisworks2/Documents/phd_paper_material/MMABPWW/SALBP_benchmark/small data set_n=20/{i}.alb\")\n",
    "    #test_g = plot_salbp_edge_removal_graph(test_salb, f\"instance_n=20_{i}\", results_df)\n",
    "    test_g = draw_graph_with_discrete_legend(test_salb, results_df, i, ax=axs[idx])\n",
    "    #adds test_g to the axs\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.x Kernel with pytorch geometric",
   "language": "python",
   "name": "pytorch_geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
