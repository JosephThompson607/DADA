{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T17:49:55.341329Z",
     "start_time": "2025-06-10T17:49:54.260241Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_alb(alb_file_name):\n",
    "    \"\"\"Reads assembly line balancing instance .alb file, returns dictionary with the information\"\"\"\n",
    "    parse_dict = {}\n",
    "    alb_file = open(alb_file_name).read()\n",
    "    # Get number of tasks\n",
    "    num_tasks = re.search(\"<number of tasks>\\n(\\\\d*)\", alb_file)\n",
    "    parse_dict[\"num_tasks\"] = int(num_tasks.group(1))\n",
    "\n",
    "    # Get cycle time\n",
    "    cycle_time = re.search(\"<cycle time>\\n(\\\\d*)\", alb_file)\n",
    "    parse_dict[\"cycle_time\"] = int(cycle_time.group(1))\n",
    "\n",
    "    # Order Strength\n",
    "    order_strength = re.search(\"<order strength>\\n(\\\\d*,\\\\d*)\", alb_file)\n",
    "    \n",
    "    if order_strength:\n",
    "        parse_dict[\"original_order_strength\"] = float(order_strength.group(1).replace(\",\", \".\"))\n",
    "    else:\n",
    "        order_strength = re.search(\"<order strength>\\n(\\\\d*.\\\\d*)\", alb_file)\n",
    "        parse_dict[\"original_order_strength\"] = float(order_strength.group(1))\n",
    "\n",
    "    # Task_times\n",
    "    task_times = re.search(\"<task times>(.|\\n)+?<\", alb_file)\n",
    "\n",
    "    # Get lines in this regex ignoring the first and last 2\n",
    "    task_times = task_times.group(0).split(\"\\n\")[1:-2]\n",
    "    task_times = {task.split()[0]: int(task.split()[1]) for task in task_times}\n",
    "    parse_dict[\"task_times\"] = task_times\n",
    "\n",
    "    # Precedence relations\n",
    "    precedence_relations = re.search(\"<precedence relations>(.|\\n)+?<\", alb_file)\n",
    "    precedence_relations = precedence_relations.group(0).split(\"\\n\")[1:-2]\n",
    "    precedence_relations = [task.split(\",\") for task in precedence_relations]\n",
    "    parse_dict[\"precedence_relations\"] = precedence_relations\n",
    "    return parse_dict\n",
    "\n",
    "def write_to_alb(salbp_dict, alb_file_name):\n",
    "    \"\"\"Writes the SALBP dictionary to an .alb file\"\"\"\n",
    "    #Format of alb:\n",
    "    # <number of tasks>\n",
    "    # no_tasks\n",
    "    # <cycle time>\n",
    "    # cycle_time\n",
    "    #<task times>\n",
    "    #task_id task_time\n",
    "    #<precedence relations>\n",
    "    #task_id,task_id\n",
    "\n",
    "\n",
    "    # Write number of tasks\n",
    "    alb = \"<number of tasks>\\n\"\n",
    "    alb += str(salbp_dict[\"num_tasks\"]) + \"\\n\"\n",
    "    # Write cycle time\n",
    "    alb += \"<cycle time>\\n\"\n",
    "    alb += str(salbp_dict[\"cycle_time\"]) + \"\\n\"\n",
    "    # Write task times\n",
    "    alb += \"<task times>\\n\"\n",
    "    for task_id, task_time in salbp_dict[\"task_times\"].items():\n",
    "        alb += task_id + \" \" + str(task_time) + \"\\n\"\n",
    "    # Write precedence relations\n",
    "    alb += \"<precedence relations>\\n\"\n",
    "    for relation in salbp_dict[\"precedence_relations\"]:\n",
    "        alb += relation[0] + \",\" + relation[1] + \"\\n\"\n",
    "    #ends the file\n",
    "    alb += \"<end>\"\n",
    "    with open(alb_file_name, \"w\") as alb_file:\n",
    "        alb_file.write(alb)\n",
    "    \n",
    "\n",
    "\n",
    "SALBP_dict = parse_alb(\"/home/jot240/MALBPW/MMABPW/SALBP_benchmark/large data set_n=100/instance_n=100_53.alb\")\n",
    "write_to_alb(SALBP_dict, \"test_large.alb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test_alb = {'num_tasks': 12,\n",
    " 'cycle_time': 10,\n",
    " 'original_order_strength': 0.268,\n",
    " 'task_times': {'1': 3,\n",
    "  '2': 8,\n",
    "  '3': 3,\n",
    "  '4': 2,\n",
    "  '5': 4,\n",
    "  '6': 2,\n",
    "  '7': 5,\n",
    "  '8': 1,\n",
    "  '9': 9,\n",
    "  '10': 4,\n",
    "  '11': 6,\n",
    "  '12': 2,\n",
    "    },\n",
    " 'precedence_relations': [\n",
    "     ['1', '5'],\n",
    "  ['2', '5'],\n",
    "  ['3', '5'],\n",
    "  ['3', '4'],\n",
    "  ['4', '9'],\n",
    "  ['5', '6'],\n",
    "  ['5', '7'],\n",
    "  ['5', '8'],\n",
    "  ['6', '11'],\n",
    "  ['7', '11'],\n",
    "  ['8', '11'],\n",
    "  ['9', '10'],\n",
    "  ['10', '12'],\n",
    "  ['11', '12']\n",
    "  ]\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SALBP_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls BBR-for-SALBP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_large.alb start at Thu Sep  4 16:32:53 2025\n",
      "\n",
      "test_large.alb\n",
      "n=100\n",
      "cycle time=1000\n",
      "t1=514 t2=389 t3=727 t4=383 t5=386 t6=467 t7=575 t8=304 t9=615 t10=474 t11=449 t12=466 t13=604 t14=344 t15=687 t16=526 t17=375 t18=542 t19=381 t20=413 t21=612 t22=457 t23=582 t24=383 t25=494 t26=442 t27=586 t28=711 t29=537 t30=405 t31=349 t32=724 t33=401 t34=556 t35=424 t36=405 t37=367 t38=518 t39=388 t40=582 t41=477 t42=681 t43=445 t44=462 t45=276 t46=435 t47=673 t48=523 t49=481 t50=380 t51=424 t52=456 t53=348 t54=720 t55=624 t56=542 t57=508 t58=641 t59=456 t60=659 t61=297 t62=590 t63=691 t64=443 t65=573 t66=385 t67=449 t68=513 t69=446 t70=621 t71=586 t72=515 t73=395 t74=276 t75=537 t76=328 t77=522 t78=587 t79=510 t80=441 t81=377 t82=400 t83=385 t84=604 t85=293 t86=558 t87=525 t88=421 t89=340 t90=534 t91=632 t92=279 t93=662 t94=407 t95=541 t96=412 t97=565 t98=507 t99=701 t100=477 \n",
      "running forward 24511824 272872600\n",
      "MHH upper bound: 53 (0.01s)\n",
      "First lower bound: 50\n",
      "Second lower bound 51\n",
      "lower bound time: 0.00s\n",
      "bin packing time: 0.00s\n",
      "   UB = 52    0.279\n",
      "Successors of task 1 with time 514:73 \n",
      "Successors of task 2 with time 389:73 \n",
      "Successors of task 3 with time 727:11 \n",
      "Successors of task 4 with time 383:11 \n",
      "Successors of task 5 with time 386:11 \n",
      "Successors of task 6 with time 467:11 \n",
      "Successors of task 7 with time 575:11 \n",
      "Successors of task 8 with time 304:12 \n",
      "Successors of task 9 with time 615:14 76 \n",
      "Successors of task 10 with time 474:13 \n",
      "Successors of task 11 with time 449:15 16 17 18 19 20 21 25 26 \n",
      "Successors of task 12 with time 466:22 \n",
      "Successors of task 13 with time 604:24 \n",
      "Successors of task 14 with time 344:23 \n",
      "Successors of task 15 with time 687:31 32 \n",
      "Successors of task 16 with time 526:29 \n",
      "Successors of task 17 with time 375:36 44 \n",
      "Successors of task 18 with time 542:28 90 \n",
      "Successors of task 19 with time 381:\n",
      "Successors of task 20 with time 413:\n",
      "Successors of task 21 with time 612:\n",
      "Successors of task 22 with time 457:\n",
      "Successors of task 23 with time 582:30 37 79 \n",
      "Successors of task 24 with time 383:27 34 35 \n",
      "Successors of task 25 with time 494:33 \n",
      "Successors of task 26 with time 442:\n",
      "Successors of task 27 with time 586:73 \n",
      "Successors of task 28 with time 711:73 \n",
      "Successors of task 29 with time 537:73 \n",
      "Successors of task 30 with time 405:41 \n",
      "Successors of task 31 with time 349:42 \n",
      "Successors of task 32 with time 724:39 40 \n",
      "Successors of task 33 with time 401:38 \n",
      "Successors of task 34 with time 556:43 \n",
      "Successors of task 35 with time 424:45 46 \n",
      "Successors of task 36 with time 405:\n",
      "Successors of task 37 with time 367:44 47 \n",
      "Successors of task 38 with time 518:73 \n",
      "Successors of task 39 with time 388:48 \n",
      "Successors of task 40 with time 582:49 \n",
      "Successors of task 41 with time 477:52 \n",
      "Successors of task 42 with time 681:50 \n",
      "Successors of task 43 with time 445:51 53 55 \n",
      "Successors of task 44 with time 462:\n",
      "Successors of task 45 with time 276:54 \n",
      "Successors of task 46 with time 435:\n",
      "Successors of task 47 with time 673:73 \n",
      "Successors of task 48 with time 523:59 \n",
      "Successors of task 49 with time 481:57 \n",
      "Successors of task 50 with time 380:60 \n",
      "Successors of task 51 with time 424:58 62 63 \n",
      "Successors of task 52 with time 456:\n",
      "Successors of task 53 with time 348:56 69 \n",
      "Successors of task 54 with time 720:\n",
      "Successors of task 55 with time 624:61 \n",
      "Successors of task 56 with time 542:73 \n",
      "Successors of task 57 with time 508:67 \n",
      "Successors of task 58 with time 641:68 \n",
      "Successors of task 59 with time 456:64 \n",
      "Successors of task 60 with time 659:64 \n",
      "Successors of task 61 with time 297:71 \n",
      "Successors of task 62 with time 590:65 66 69 72 \n",
      "Successors of task 63 with time 691:70 \n",
      "Successors of task 64 with time 443:73 \n",
      "Successors of task 65 with time 573:73 \n",
      "Successors of task 66 with time 385:73 \n",
      "Successors of task 67 with time 449:74 \n",
      "Successors of task 68 with time 513:75 \n",
      "Successors of task 69 with time 446:78 \n",
      "Successors of task 70 with time 621:79 \n",
      "Successors of task 71 with time 586:76 77 80 \n",
      "Successors of task 72 with time 515:\n",
      "Successors of task 73 with time 395:81 82 83 84 85 92 \n",
      "Successors of task 74 with time 276:88 \n",
      "Successors of task 75 with time 537:86 \n",
      "Successors of task 76 with time 328:87 89 \n",
      "Successors of task 77 with time 522:91 \n",
      "Successors of task 78 with time 587:90 \n",
      "Successors of task 79 with time 510:\n",
      "Successors of task 80 with time 441:100 \n",
      "Successors of task 81 with time 377:\n",
      "Successors of task 82 with time 400:96 \n",
      "Successors of task 83 with time 385:\n",
      "Successors of task 84 with time 604:\n",
      "Successors of task 85 with time 293:\n",
      "Successors of task 86 with time 558:94 \n",
      "Successors of task 87 with time 525:93 \n",
      "Successors of task 88 with time 421:\n",
      "Successors of task 89 with time 340:99 \n",
      "Successors of task 90 with time 534:\n",
      "Successors of task 91 with time 632:95 \n",
      "Successors of task 92 with time 279:\n",
      "Successors of task 93 with time 662:97 \n",
      "Successors of task 94 with time 407:98 \n",
      "Successors of task 95 with time 541:100 \n",
      "Successors of task 96 with time 412:99 \n",
      "Successors of task 97 with time 565:\n",
      "Successors of task 98 with time 507:\n",
      "Successors of task 99 with time 701:\n",
      "Successors of task 100 with time 477:\n",
      "     10000      46490      56490 41 1909  79     46.141\n",
      "     20000      74199      94199 13  219  27     15.386\n",
      "     30000     104006     134006 25  670  49     25.780\n",
      "     40000     133915     173915 22  559  45     24.309\n",
      "     50000     163496     213496 16  272  32     15.640\n",
      "     60000     194325     254325 21  381  42     16.983\n",
      "     70000     229638     299638 36  804  71     21.753\n",
      "     80000     264489     344489 37 1008  73     26.703\n",
      "     90000     296938     386938 28  679  55     23.350\n",
      "    100000     329467     429467 26  652  51     24.097\n",
      "    110000     362257     472257 21  384  42     17.126\n",
      "    120000     395593     515593 24  653  47     26.148\n",
      "    130000     430322     560322 24  655  47     26.232\n",
      "    140000     467246     607246 36  876  71     23.753\n",
      "    150000     499187     649187 28  691  55     23.779\n",
      "    160000     529282     689282 36  873  71     23.670\n",
      "    170000     559811     729811 19  339  38     16.602\n",
      "    180000     590608     770608 12  252  24     19.480\n",
      "    190000     619946     809946 31  755  61     23.575\n",
      "    200000     650054     850054 25  663  49     25.500\n",
      "    210000     685160     895160 25  664  49     25.540\n",
      "    220000     718818     938818 38 1309  74     33.927\n",
      "    230000     748724     978724 39 1708  75     43.295\n",
      "    240000     776746    1016746 11  257  22     21.804\n",
      "    250000     804057    1054057 30  749  59     24.147\n",
      "    260000     839063    1099063 27  626  54     22.265\n",
      "    270000     880453    1150453 20  390  40     18.300\n",
      "    280000     919049    1199049 35  737  69     20.437\n",
      "    290000     955385    1245385 40 1856  76     45.920\n",
      "    300000     991567    1291567 21  361  42     16.030\n",
      "Time limit reached\n",
      "Time limit reached\n",
      "Solution with 52 stations\n",
      " 1\t1\n",
      "2\t2\n",
      "3\t25\n",
      "4\t21\n",
      "5\t16\n",
      "6\t7\n",
      "7\t4\n",
      "8\t19\n",
      "9\t3\n",
      "10\t1\n",
      "11\t26\n",
      "12\t20\n",
      "13\t2\n",
      "14\t11\n",
      "15\t34\n",
      "16\t29\n",
      "17\t28\n",
      "18\t26\n",
      "19\t52\n",
      "20\t27\n",
      "21\t28\n",
      "22\t23\n",
      "23\t12\n",
      "24\t3\n",
      "25\t32\n",
      "26\t30\n",
      "27\t21\n",
      "28\t40\n",
      "29\t30\n",
      "30\t12\n",
      "31\t42\n",
      "32\t35\n",
      "33\t33\n",
      "34\t6\n",
      "35\t4\n",
      "36\t31\n",
      "37\t15\n",
      "38\t37\n",
      "39\t36\n",
      "40\t36\n",
      "41\t13\n",
      "42\t43\n",
      "43\t7\n",
      "44\t29\n",
      "45\t5\n",
      "46\t6\n",
      "47\t19\n",
      "48\t38\n",
      "49\t37\n",
      "50\t44\n",
      "51\t9\n",
      "52\t14\n",
      "53\t8\n",
      "54\t5\n",
      "55\t8\n",
      "56\t9\n",
      "57\t39\n",
      "58\t11\n",
      "59\t38\n",
      "60\t45\n",
      "61\t10\n",
      "62\t18\n",
      "63\t10\n",
      "64\t46\n",
      "65\t31\n",
      "66\t41\n",
      "67\t39\n",
      "68\t13\n",
      "69\t24\n",
      "70\t15\n",
      "71\t16\n",
      "72\t41\n",
      "73\t47\n",
      "74\t40\n",
      "75\t14\n",
      "76\t22\n",
      "77\t20\n",
      "78\t27\n",
      "79\t42\n",
      "80\t17\n",
      "81\t52\n",
      "82\t49\n",
      "83\t50\n",
      "84\t47\n",
      "85\t48\n",
      "86\t17\n",
      "87\t24\n",
      "88\t46\n",
      "89\t45\n",
      "90\t33\n",
      "91\t22\n",
      "92\t51\n",
      "93\t48\n",
      "94\t18\n",
      "95\t23\n",
      "96\t50\n",
      "97\t49\n",
      "98\t44\n",
      "99\t51\n",
      "100\t32\n",
      "test_large test_large test_large.sol\n",
      "   verified_optimality = 0; value = 52; cpu = 10.11\n",
      "   ************* DID NOT VERIFY OPTIMALITY ************\n",
      "Hoffman cpu =   0.01  best_first_bbr cpu =   9.99  bfs_bbr cpu =   0.10 find_insert_cpu =   2.48  bin_cpu =   0.00  cpu =  10.11\n",
      "\n",
      "test_large end at Thu Sep  4 16:33:04 2025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! ../BBR-for-SALBP1/SALB/SALB/salb  -p 2 -t 10 \"test_large.alb\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.alb\n",
      "n=50\n",
      "cycle time=1000\n",
      "t1=384 t2=493 t3=696 t4=566 t5=576 t6=696 t7=637 t8=804 t9=604 t10=492 t11=551 t12=788 t13=320 t14=583 t15=708 t16=558 t17=564 t18=592 t19=600 t20=586 t21=611 t22=483 t23=417 t24=463 t25=343 t26=461 t27=578 t28=427 t29=518 t30=575 t31=628 t32=442 t33=405 t34=430 t35=334 t36=452 t37=371 t38=574 t39=442 t40=366 t41=196 t42=390 t43=529 t44=372 t45=698 t46=564 t47=489 t48=330 t49=373 t50=581 \n",
      "running forward 2383920 56711200\n",
      "MHH upper bound: 29 (0.00s)\n",
      "First lower bound: 26\n",
      "Second lower bound 27\n",
      "lower bound time: 0.00s\n",
      "bin packing time: 0.00s\n",
      "     10000      10908      20908 16 1489  28     92.623\n",
      "     20000      20221      40221 18 1642  32     90.862\n",
      "     30000      30902      60902 11 2189  16    198.320\n",
      "     40000      38437      78437 16 1619  28    100.748\n",
      "     50000      44759      94759 16 1655  28    102.998\n",
      "     60000      53027     113027 20 1813  36     90.370\n",
      "     70000      61607     131607 13 1769  21    135.497\n",
      "     80000      68162     148162 18 1804  32     99.862\n",
      "     90000      72468     162468 19 1816  34     95.259\n",
      "    100000      77268     177268 18 1822  31    100.842\n",
      "    110000      81153     191153 15 1736  26    115.253\n",
      "    120000      83995     203995 17 1778  30    104.188\n",
      "    130000      86783     216783 13 1946  21    149.112\n",
      "    140000      90205     230205 19 1922  34    100.838\n",
      "    150000      96719     246719 18 1834  31    101.509\n",
      "    160000     101996     261996 15 1776  25    117.900\n",
      "    170000     105838     275838 17 1809  30    106.012\n",
      "    180000     108701     288701 18 1876  31    103.842\n",
      "    190000     109960     299960 15 1796  25    119.233\n",
      "    200000     110361     310361 13 2239  20    171.631\n",
      "    210000     109873     319873 14 1876  23    133.460\n",
      "    220000     108618     328618 18 1899  31    105.120\n",
      "    230000     108354     338354 19 2023  33    106.134\n",
      "    240000     107450     347450 17 1846  30    108.188\n",
      "    250000     106328     356328 14 1951  23    138.817\n",
      "    260000     105122     365122 17 1857  29    108.815\n",
      "    270000     104418     374418 18 1935  31    107.120\n",
      "    280000     105715     385715 15 1863  25    123.700\n",
      "    290000     108549     398549 15 1872  25    124.300\n",
      "    300000     110450     410450 18 1947  31    107.787\n",
      "    310000     111865     421865 16 1861  28    115.873\n",
      "    320000     112573     432573 15 1898  26    126.053\n",
      "    330000     112488     442488 17 1895  30    111.071\n",
      "    340000     111853     451853 17 1885  29    110.462\n",
      "    350000     110312     460312 16 1885  27    117.353\n",
      "    360000     108454     468454 14 2219  22    157.940\n",
      "    370000     105659     475659 16 1898  27    118.165\n",
      "    380000     102343     482343 19 2076  33    108.923\n",
      "    390000      98712     488712 14 2274  22    161.869\n",
      "    400000      94721     494721 14 2297  22    163.511\n",
      "    410000      90381     500381 17 1942  29    113.815\n",
      "    420000      87173     507173 15 2050  25    136.167\n",
      "    430000      86481     516481 17 1959  30    114.835\n",
      "    440000      86794     526794 16 1956  27    121.790\n",
      "    450000      86962     536962 16 1968  27    122.540\n",
      "    460000      86984     546984 17 1989  29    116.580\n",
      "    470000      86740     556740 16 1995  27    124.228\n",
      "    480000      85749     565749 17 2013  29    117.992\n",
      "    490000      84295     574295 19 2092  33    109.765\n",
      "    500000      82295     582295 17 2041  29    119.639\n",
      "    510000      80426     590426 17 2057  29    120.580\n",
      "    520000      78916     598916 21 2264  36    107.530\n",
      "    530000      77766     607766 15 2239  24    148.747\n",
      "    540000      77034     617034 18 2153  31    119.231\n",
      "    550000      76483     626483 17 2121  29    124.345\n",
      "    560000      76143     636143 19 2251  33    118.134\n",
      "    570000      75268     645268 16 2155  27    134.227\n",
      "    580000      74081     654081 17 2156  29    126.404\n",
      "    590000      72959     662959 17 2166  29    126.992\n",
      "    600000      71222     671222 17 2176  29    127.580\n",
      "    610000      68913     678913 16 2190  26    136.395\n",
      "    620000      66350     686350 19 2345  32    123.061\n",
      "    630000      65185     695185 17 2205  28    129.266\n",
      "    640000      63141     703141 17 2215  29    129.874\n",
      "    650000      60496     710496 19 2290  33    120.186\n",
      "    660000      56869     716869 19 2344  32    123.008\n",
      "    670000      52366     722366 18 2291  30    126.878\n",
      "    680000      46987     726987 18 2327  30    128.878\n",
      "    690000      40489     730489 17 2266  28    132.854\n",
      "    700000      33450     733450 18 2360  30    130.711\n",
      "    710000      26148     736148 16 2304  26    143.520\n",
      "    720000      17794     737794 17 2305  28    135.148\n",
      "    730000       8446     738446 16 2355  26    146.708\n",
      "Solution with 30 stations\n",
      " 1\t1\n",
      "2\t2\n",
      "3\t7\n",
      "4\t19\n",
      "5\t1\n",
      "6\t25\n",
      "7\t22\n",
      "8\t4\n",
      "9\t20\n",
      "10\t2\n",
      "11\t3\n",
      "12\t5\n",
      "13\t3\n",
      "14\t16\n",
      "15\t6\n",
      "16\t9\n",
      "17\t27\n",
      "18\t17\n",
      "19\t28\n",
      "20\t15\n",
      "21\t8\n",
      "22\t30\n",
      "23\t16\n",
      "24\t12\n",
      "25\t21\n",
      "26\t29\n",
      "27\t10\n",
      "28\t9\n",
      "29\t18\n",
      "30\t26\n",
      "31\t13\n",
      "32\t18\n",
      "33\t17\n",
      "34\t19\n",
      "35\t13\n",
      "36\t12\n",
      "37\t10\n",
      "38\t11\n",
      "39\t21\n",
      "40\t11\n",
      "41\t21\n",
      "42\t20\n",
      "43\t29\n",
      "44\t23\n",
      "45\t14\n",
      "46\t24\n",
      "47\t30\n",
      "48\t22\n",
      "49\t24\n",
      "50\t23\n",
      "test test test.sol\n",
      "   verified_optimality = 1; value = 29; cpu = 16.22\n",
      "Hoffman cpu =   0.00  best_first_bbr cpu =  16.87  bfs_bbr cpu =   0.00 find_insert_cpu =   5.04  bin_cpu =   0.00  cpu =  16.22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SALBP_dict = parse_alb(\"/Users/letshopethisworks2/Documents/phd_paper_material/MMABPWW/SALBP_benchmark/medium data set_n=50/instance_n=50_331.alb\")\n",
    "write_to_alb(SALBP_dict, \"test.alb\")\n",
    "\n",
    "! ./salb_d \"test.alb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def random_task_time_change(SALBP_dict, multiplier = 1.5):\n",
    "    \"\"\"Increases a random task time by 1\"\"\"\n",
    "    import random\n",
    "    task_id = random.choice(list(SALBP_dict[\"task_times\"].keys()))\n",
    "    SALBP_dict[\"task_times\"][task_id] *= multiplier\n",
    "    return SALBP_dict\n",
    "\n",
    "def task_time_change(SALBP_dict, task_id, multiplier = 1.5, debug = False):\n",
    "    \"\"\"Increases a random task time by 1\"\"\"\n",
    "    if debug:\n",
    "        print(\"Changing task\", task_id, \"time by\", multiplier)\n",
    "    SALBP_dict[\"task_times\"][task_id] *= multiplier\n",
    "    return SALBP_dict\n",
    "\n",
    "def precedence_removal(SALBP_dict, edge_index):\n",
    "    \"\"\"Removes a precedence relation\"\"\"\n",
    "    SALBP_dict[\"precedence_relations\"].pop(edge_index)\n",
    "    return SALBP_dict\n",
    "    \n",
    "\n",
    "def parse_bb_salb1_out(text):\n",
    "    '''gets the number of stations, optimal flag and cpu time from the output of the salb1 program'''\n",
    "    output = text.stdout.decode(\"utf-8\")\n",
    "    # Regular expression to capture the required values\n",
    "    match = re.search(r\"verified_optimality\\s*=\\s*(\\d+);\\s*value\\s*=\\s*(\\d+);\\s*cpu\\s*=\\s*([\\d.]+)\", output)\n",
    "\n",
    "    if match:\n",
    "        verified_optimality = int(match.group(1))\n",
    "        value = int(match.group(2))\n",
    "        cpu = float(match.group(3))\n",
    "\n",
    "    else:\n",
    "        print(\"Pattern not found.\")\n",
    "    return value, verified_optimality, cpu\n",
    "\n",
    "def generate_results(fp = \"/Users/letshopethisworks2/Documents/phd_paper_material/MALBP_instance_generation/SALBP_benchmark/small data set_n=20/\" ,  instance_name = \"instance_n=20_\", ext = \".alb\", start=1, stop = 300):\n",
    "    results = []\n",
    "    for i in range(start,stop):\n",
    "        SALBP_dict_orig = parse_alb(f\"{fp}{instance_name}{i}{ext}\")\n",
    "        bin_dict = deepcopy(SALBP_dict_orig)\n",
    "        print(\"Running instance: \", i)\n",
    "        for j in range(len(SALBP_dict_orig[\"precedence_relations\"])):\n",
    "            SALBP_dict = deepcopy(SALBP_dict_orig)\n",
    "            SALBP_dict =precedence_removal(SALBP_dict, j)\n",
    "            write_to_alb(SALBP_dict, \"test.alb\")\n",
    "            output = subprocess.run([ex_fp, \"test.alb\"], stdout=subprocess.PIPE)\n",
    "            no_stations, optimal, cpu = parse_bb_salb1_out(output)\n",
    "            result = {\"instance:\": f\"instance_n=20_{i}\", \"precedence_relation\": j, \"no_stations\": no_stations, \"optimal\": optimal, \"cpu\": cpu}\n",
    "            save_backup(backup_name, result)\n",
    "            results.append(result)\n",
    "\n",
    "        #calculates bin packing lower bound\n",
    "        bin_dict['precedence_relations'] = []\n",
    "        write_to_alb(bin_dict, \"test.alb\")\n",
    "        output = subprocess.run([ex_fp, \"test.alb\"], stdout=subprocess.PIPE)\n",
    "        no_stations, optimal, cpu = parse_bb_salb1_out(output)\n",
    "        result = {\"instance:\": f\"instance_n=20_{i}\", \"precedence_relation\": \"None\", \"no_stations\": no_stations, \"optimal\": optimal, \"cpu\": cpu}\n",
    "        save_backup(backup_name, result)\n",
    "            \n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "#reads the results csv\n",
    "#results_df = pd.read_csv(\"task_20_bin_lb.csv\")\n",
    "#results_df = pd.DataFrame(results)\n",
    "#saves the results df to a csv file\n",
    "#results_df.to_csv(\"tasks20_test.csv\")\n",
    "# results = generate_results(start=400, stop = 525)\n",
    "# results_df = pd.DataFrame(results)\n",
    "# results_df.to_csv(\"tasks20_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_1 = pd.read_csv(\"task_20_bin_lb.csv\")\n",
    "res_2 = pd.read_csv(\"tasks20_2.csv\")\n",
    "res_3 = pd.read_csv(\"tasks20_3.csv\")\n",
    "\n",
    "results_df = pd.concat([res_1, res_2, res_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_df = results_df[results_df[\"precedence_relation\"].isna() == True].copy()\n",
    "#removes the rows with None precedence relations\n",
    "results_df = results_df[results_df['precedence_relation'].isna() == False]\n",
    "\n",
    "lb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets the min and max number of stations for each instance\n",
    "min_and_max = results_df.groupby(\"instance:\")[\"no_stations\"].agg([\"min\", \"max\"])\n",
    "min_and_max.reset_index(inplace = True)\n",
    "#adds in lb values\n",
    "lb_df['bin_lb'] = lb_df['no_stations']\n",
    "min_and_max = pd.merge(min_and_max, lb_df[[\"instance:\", \"bin_lb\"]], on = \"instance:\")\n",
    "min_and_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts the number of times min does not equal max\n",
    "min_and_max[\"min_not_equal_max\"] = min_and_max[\"min\"] != min_and_max[\"max\"]\n",
    "min_and_max[\"min_not_equal_max\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts the number of time the bin_lb is less than the min\n",
    "min_and_max[\"bin_lb_less_than_min\"] = min_and_max[\"bin_lb\"] < min_and_max[\"min\"]\n",
    "min_and_max[\"bin_lb_less_than_min\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts the number of time the bin_lb is less than the max\n",
    "min_and_max[\"bin_lb_less_than_max\"] = min_and_max[\"bin_lb\"] < min_and_max[\"max\"]\n",
    "print(\"bin lb dif\", min_and_max[\"bin_lb_less_than_max\"].sum())\n",
    "#filters for the instances where the bin_lb is les than the max\n",
    "min_and_max[min_and_max[\"bin_lb_less_than_max\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints the instances where min does not equal max\n",
    "interesting_instances = min_and_max[min_and_max[\"min_not_equal_max\"]]\n",
    "interesting_instances['instance:'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_20_101 = results_df[results_df[\"instance:\"] == \"instance_n=20_101\"]\n",
    "inst_20_101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/letshopethisworks2/Documents/phd_paper_material/MMABPWW/SALBP_benchmark/small data set_n=20/instance_n=20_1.alb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 103\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m G\n\u001b[1;32m    101\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 103\u001b[0m test_salb \u001b[38;5;241m=\u001b[39m \u001b[43mparse_alb\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/letshopethisworks2/Documents/phd_paper_material/MMABPWW/SALBP_benchmark/small data set_n=20/instance_n=20_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.alb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m#test_g = plot_salbp_edge_removal_graph(test_salb, f\"instance_n=20_{i}\", results_df)\u001b[39;00m\n\u001b[1;32m    105\u001b[0m test_g \u001b[38;5;241m=\u001b[39m draw_graph_with_discrete_legend(test_salb, results_df, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance_n=20_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m, in \u001b[0;36mparse_alb\u001b[0;34m(alb_file_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reads assembly line balancing instance .alb file, returns dictionary with the information\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m parse_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 4\u001b[0m alb_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43malb_file_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Get number of tasks\u001b[39;00m\n\u001b[1;32m      6\u001b[0m num_tasks \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<number of tasks>\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124md*)\u001b[39m\u001b[38;5;124m\"\u001b[39m, alb_file)\n",
      "File \u001b[0;32m~/jupyter_py3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/letshopethisworks2/Documents/phd_paper_material/MMABPWW/SALBP_benchmark/small data set_n=20/instance_n=20_1.alb'"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def plot_salbp_graph(SALBP_dict):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(SALBP_dict[\"task_times\"].keys())\n",
    "    G.add_edges_from(SALBP_dict[\"precedence_relations\"])\n",
    "    #prints the edges\n",
    "    print(\"from dict\", SALBP_dict[\"precedence_relations\"])\n",
    "    #prints the edges from the graph\n",
    "    print(\"from graph\", G.edges())\n",
    "    nx.draw(G, with_labels = True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_salbp_edge_removal_graph(SALBP_dict, instance_name, res_df):\n",
    "    '''Colors the edges by the number of stations in res_df'''\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(SALBP_dict[\"task_times\"].keys())\n",
    "    G.add_edges_from(SALBP_dict[\"precedence_relations\"])\n",
    "    edge_colors = []\n",
    "    for edge in G.edges():\n",
    "        edge_index = SALBP_dict[\"precedence_relations\"].index(list(edge))\n",
    "        no_stations = res_df[(res_df[\"instance:\"] == instance_name) & (res_df[\"precedence_relation\"] == edge_index)][\"no_stations\"].values[0]\n",
    "        edge_colors.append(no_stations)\n",
    "    #saves edge colors as graph attribute\n",
    "    nx.set_edge_attributes(G, dict(zip(G.edges(), edge_colors)), \"value\")\n",
    "    pos = nx.nx_pydot.graphviz_layout(G, prog = \"dot\")\n",
    "   # Define colormap\n",
    "    unique_values = list(set(edge_colors))\n",
    "    print(unique_values)\n",
    "    color_map = cm.get_cmap('viridis', len(unique_values))\n",
    "    print(\"color map\", color_map)\n",
    "    cmap = mcolors.ListedColormap([color_map(val) for val in unique_values])\n",
    "\n",
    "    # Draw graph\n",
    "    #creates ax\n",
    "    fig, ax = plt.subplots()\n",
    "    edges = nx.draw_networkx_edges(G, pos, edge_color=edge_colors, edge_cmap=cmap, edge_vmin=min(edge_colors), edge_vmax=max(edge_colors), ax=ax)\n",
    "    nx.draw_networkx_nodes(G, pos, ax=ax)\n",
    "    nx.draw_networkx_labels(G, pos, ax=ax)\n",
    "\n",
    "    # Add colorbar\n",
    "    handles = [plt.Line2D([0], [0], marker='o', color = color_map(val), label=val, markersize=10) for val in unique_values]\n",
    "    plt.legend(handles=handles, loc=\"best\")\n",
    "\n",
    "    plt.show()\n",
    "    return G\n",
    "\n",
    "\n",
    "def draw_graph_with_discrete_legend(SALBP_dict, res_df, instance_name,  ax=None):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(SALBP_dict[\"task_times\"].keys())\n",
    "    G.add_edges_from(SALBP_dict[\"precedence_relations\"])\n",
    "\n",
    "    edge_colors = []\n",
    "    edge_values = []  # Store unique edge values for legend\n",
    "\n",
    "    for edge in G.edges():\n",
    "        edge_index = SALBP_dict[\"precedence_relations\"].index(list(edge))\n",
    "        no_stations = res_df[(res_df[\"instance:\"] == instance_name) & \n",
    "                             (res_df[\"precedence_relation\"] == edge_index)][\"no_stations\"].values[0]\n",
    "        edge_colors.append(no_stations)\n",
    "        if no_stations not in edge_values:\n",
    "            edge_values.append(no_stations)\n",
    "\n",
    "    # Save edge colors as graph attribute\n",
    "    nx.set_edge_attributes(G, dict(zip(G.edges(), edge_colors)), \"value\")\n",
    "\n",
    "    # Graph layout\n",
    "    pos = nx.nx_pydot.graphviz_layout(G, prog=\"dot\")\n",
    "\n",
    "    # Define discrete colormap\n",
    "    unique_values = sorted(edge_values)\n",
    "    num_colors = len(unique_values)\n",
    "    cmap = plt.cm.get_cmap(\"Set1\", num_colors)  # Use a qualitative colormap\n",
    "    color_map = {val: cmap(i) for i, val in enumerate(unique_values)}  # Assign colors to unique values\n",
    "\n",
    "    # Assign discrete colors to edges\n",
    "    edge_color_list = [color_map[val] for val in edge_colors]\n",
    "\n",
    "    # Draw graph\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    edges = nx.draw_networkx_edges(G, pos, edge_color=edge_color_list, ax=ax)\n",
    "    nx.draw_networkx_nodes(G, pos, ax=ax)\n",
    "    nx.draw_networkx_labels(G, pos, ax=ax)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    # Create legend\n",
    "    handles = [plt.Line2D([0], [0], color=color_map[val], lw=2, label=f\"No. of Stations: {val}\") for val in unique_values]\n",
    "    #ax.legend(handles=handles, loc=\"best\")\n",
    "\n",
    "\n",
    "    return G\n",
    "\n",
    "i = 1\n",
    "\n",
    "test_salb = parse_alb(f\"/Users/letshopethisworks2/Documents/phd_paper_material/MMABPWW/SALBP_benchmark/small data set_n=20/instance_n=20_{i}.alb\")\n",
    "#test_g = plot_salbp_edge_removal_graph(test_salb, f\"instance_n=20_{i}\", results_df)\n",
    "test_g = draw_graph_with_discrete_legend(test_salb, results_df, f\"instance_n=20_{i}\")\n",
    "#saves graph to a gephi readable file\n",
    "nx.write_gexf(test_g, \"test_salb.gexf\")\n",
    "#plot_salbp_graph(test_salb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_instances['instance:'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a plot of the 27 graphs of interest\n",
    "fig, axs = plt.subplots(5, 11, figsize=(20, 20))\n",
    "axs = axs.ravel()\n",
    "for idx, i in enumerate(interesting_instances['instance:'].values):\n",
    "    test_salb = parse_alb(f\"/Users/letshopethisworks2/Documents/phd_paper_material/MALBP_instance_generation/SALBP_benchmark/small data set_n=20/{i}.alb\")\n",
    "    #test_g = plot_salbp_edge_removal_graph(test_salb, f\"instance_n=20_{i}\", results_df)\n",
    "    test_g = draw_graph_with_discrete_legend(test_salb, results_df, i, ax=axs[idx])\n",
    "    #adds test_g to the axs\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_50 = pd.read_csv(\"SALBP_edge_solutions.csv\")\n",
    "# #changes 20 in instance: to 50\n",
    "# results_50['instance:'] = results_50['instance:'].str.replace(\"20\", \"50\")\n",
    "# #creates a seperate dataframe for the instances with None precedence relations\n",
    "# lb_df_50 = results_50[results_50[\"precedence_relation\"].isna() == True].copy()\n",
    "# #removes the rows with None precedence relations\n",
    "# results_50 = results_50[results_50['precedence_relation'].isna() == False]\n",
    "# #gets the min and max number of stations for each instance\n",
    "# min_and_max_50 = results_50.groupby(\"instance:\")[\"no_stations\"].agg([\"min\", \"max\"])\n",
    "# min_and_max_50.reset_index(inplace = True)\n",
    "# #adds in lb values\n",
    "# lb_df_50['bin_lb'] = lb_df_50['no_stations']\n",
    "# min_and_max_50 = pd.merge(min_and_max_50, lb_df_50[[\"instance:\", \"bin_lb\"]], on = \"instance:\")\n",
    "# #counts the number of times min does not equal max\n",
    "# min_and_max_50[\"min_not_equal_max\"] = min_and_max_50[\"min\"] != min_and_max_50[\"max\"]\n",
    "# min_and_max_50[\"min_not_equal_max\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks at instances where the min is not equal to the max\n",
    "# interesting_instances_50 = min_and_max_50[min_and_max_50[\"min_not_equal_max\"]]\n",
    "# interesting_instances_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df\n",
    "#merges min and max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merges results with min and max\n",
    "results_df = pd.merge(results_df, min_and_max, on = \"instance:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_50_1 = pd.read_csv(\"med_50/instances_50_1_through_331.csv\")\n",
    "tasks_50_2 = pd.read_csv(\"med_50/instances_50_331through399.csv\")\n",
    "tasks_50_3 = pd.read_csv(\"med_50/instances_50_400through524.csv\")\n",
    "tasks_50 = pd.concat([ tasks_50_1, tasks_50_2, tasks_50_3])\n",
    "tasks_50.head()\n",
    "\n",
    "#reads the xlsx file\n",
    "task_50_details = pd.read_excel(\"med_50/Details of the medium data set (n=50 and n=50permuted).xlsx\")\n",
    "task_50_details.head()\n",
    "\n",
    "#first row is the columns\n",
    "task_50_details.columns = task_50_details.iloc[0]\n",
    "#removes the first row\n",
    "task_50_details = task_50_details.iloc[1:]\n",
    "task_50_details.head()\n",
    "\n",
    "\n",
    "#removes <> and whitespace from the columns\n",
    "task_50_details.columns = task_50_details.columns.str.replace(\"<\", \"\").str.replace(\">\", \"\").str.strip()\n",
    "task_50_details.columns\n",
    "#left merges on instance: and Filename columns\n",
    "tasks_50 = pd.merge(tasks_50, task_50_details, left_on = \"instance:\", right_on = \"Filename\")\n",
    "tasks_50.head()\n",
    "#drops the Filename column and Unnamed: 0\n",
    "tasks_50.drop(columns = [\"Filename\", \"Unnamed: 0\"], inplace = True)\n",
    "tasks_50.head()\n",
    "\n",
    "\n",
    "#puts the rows with no_stations as none in a seperate dataframe\n",
    "lb_df_50 = tasks_50[tasks_50[\"precedence_relation\"].isna() == True].copy()\n",
    "#removes the rows with None precedence relations\n",
    "tasks_50 = tasks_50[tasks_50['precedence_relation'].isna() == False]\n",
    "#gets the min and max number of stations for each instance\n",
    "min_and_max_50 = tasks_50.groupby(\"instance:\")[\"no_stations\"].agg([\"min\", \"max\"])\n",
    "min_and_max_50.reset_index(inplace = True)\n",
    "# #renames the min and max columns as lowest_cost and original_optimal\n",
    "min_and_max_50.rename(columns = {\"min\": \"lowest_cost\", \"max\": \"original_optimal\"}, inplace = True)\n",
    "# #merges min and max with the tasks_50 dataframe\n",
    "lb_df_50['bin_lb'] = lb_df_50['no_stations']\n",
    "min_and_max_50 = pd.merge(min_and_max_50, lb_df_50[[\"instance:\", \"bin_lb\"]], on = \"instance:\")\n",
    "tasks_50 = pd.merge(tasks_50, min_and_max_50, on = \"instance:\")\n",
    "# #adds in lb values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets the instances where min and max have a gap of more than 1\n",
    "bad_eggs = min_and_max_50[min_and_max_50[\"original_optimal\"] - min_and_max_50[\"lowest_cost\"] > 1]\n",
    "bad_eggs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_and_max_50[min_and_max_50[\"instance:\"] == \"instance_n=50_31\"\t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates bins for order strength 0-0.2, 0.2-0.4, 0.4-0.6, 0.6-0.8, 0.8-1\n",
    "tasks_50['order_strength_bins'] = pd.cut(tasks_50['Order strength'], bins = [0, 0.2, 0.4, 0.6, 0.8, 1], labels = [\"0-0.2\", \"0.2-0.4\", \"0.4-0.6\", \"0.6-0.8\", \"0.8-1\"])\n",
    "tasks_50['min_not_equal_max'] = tasks_50[\"lowest_cost\"] != tasks_50[\"original_optimal\"]\n",
    "tasks_50['bin_lb_less_than_min'] = tasks_50[\"bin_lb\"] < tasks_50[\"lowest_cost\"]\n",
    "tasks_50['bin_lb_less_than_max'] = tasks_50[\"bin_lb\"] < tasks_50[\"original_optimal\"]\n",
    "tasks_50['bin_lb_less_than_max'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intereseting_50 = tasks_50[tasks_50[\"min_not_equal_max\"] == True]\n",
    "boring_50 = tasks_50[tasks_50[\"min_not_equal_max\"] == False]\n",
    "print(\"interesting\", intereseting_50['instance:'].nunique(), \"boring\", boring_50['instance:'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_chain_containing_node(G, node):\n",
    "    if node not in G:\n",
    "        return 0\n",
    "\n",
    "    # Step 1: Get longest path to `node`\n",
    "    longest_to_node = {n: 0 for n in G}  # Dictionary to store longest path to each node\n",
    "    for n in nx.topological_sort(G):  # Process in topological order\n",
    "        for pred in G.predecessors(n):\n",
    "            longest_to_node[n] = max(longest_to_node[n], longest_to_node[pred] + 1)\n",
    "\n",
    "    # Step 2: Get longest path from `node`\n",
    "    longest_from_node = {n: 0 for n in G}  # Dictionary to store longest path from each node\n",
    "    for n in reversed(list(nx.topological_sort(G))):  # Process in reverse topological order\n",
    "        for succ in G.successors(n):\n",
    "            longest_from_node[n] = max(longest_from_node[n], longest_from_node[succ] + 1)\n",
    "\n",
    "    # Step 3: Compute total longest chain containing the node\n",
    "    return longest_to_node[node] + longest_from_node[node] + 1  # +1 to include the node itself\n",
    "\n",
    "\n",
    "def get_longest_chains_edges(G):\n",
    "    # Step 1: Get longest path to `node`\n",
    "    longest_to_node = {n: 0 for n in G}  # Dictionary to store longest path to each node\n",
    "    for n in nx.topological_sort(G):  # Process in topological order\n",
    "        for pred in G.predecessors(n):\n",
    "            longest_to_node[n] = max(longest_to_node[n], longest_to_node[pred] + 1)\n",
    "\n",
    "    # Step 2: Get longest path from `node`\n",
    "    longest_from_node = {n: 0 for n in G}  # Dictionary to store longest path from each node\n",
    "    for n in reversed(list(nx.topological_sort(G))):  # Process in reverse topological order\n",
    "        for succ in G.successors(n):\n",
    "            longest_from_node[n] = max(longest_from_node[n], longest_from_node[succ] + 1)\n",
    "    edge_list = []\n",
    "    # Step 3: Compute total longest chain containing the edge\n",
    "    for edge in G.edges():\n",
    "        edge_list.append((edge, longest_to_node[edge[0]] + longest_from_node[edge[1]] + 1))\n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from([(0, 1), (0, 2), (1, 3), (2, 3), (3, 4), (5,6), (2,6)] )\n",
    "#adds node attributes \"weight to the nodes\"\n",
    "\n",
    "for node in G.nodes():\n",
    "    G.nodes[node][\"weight\"] = random.randint(1, 10)\n",
    "\n",
    "for n in nx.topological_sort(G):\n",
    "    print(n)\n",
    "\n",
    "#draws the graph\n",
    "nx.draw(G, with_labels = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_all_positional_weight(G):\n",
    "    '''Gets the positional weight of the graph'''\n",
    "    positional_weight = {}\n",
    "    trans_G = nx.transitive_closure(G)\n",
    "    #positional weight is the weight of the node plus the weight of its children\n",
    "    for node in trans_G.nodes():\n",
    "        positional_weight[node] = trans_G.nodes[node][\"weight\"]\n",
    "        for child in trans_G.neighbors(node):\n",
    "            positional_weight[node] += trans_G.nodes[child][\"weight\"]\n",
    "    return positional_weight\n",
    "\n",
    "def get_all_reverse_positional_weight(G):\n",
    "    '''Gets the reverse positional weight of the graph'''\n",
    "    rev_G = G.reverse()\n",
    "    rpw = get_all_positional_weight(rev_G)\n",
    "    return rpw\n",
    "\n",
    "def get_all_children(G):\n",
    "    '''Gets all the children of the nodes in the  graph'''\n",
    "    children_dict = {}\n",
    "    for node in G.nodes():\n",
    "        children_dict[node] = list(G.successors(node))\n",
    "    return children_dict\n",
    "\n",
    "def get_all_parents(G):\n",
    "    '''Gets all the parents of the nodes in the graph'''\n",
    "    parents_dict = {}\n",
    "    for node in G.nodes():\n",
    "        parents_dict[node] = list(G.predecessors(node))\n",
    "    return parents_dict\n",
    "\n",
    "def get_all_succesors(G):\n",
    "    '''Gets all the succesors of the nodes in the graph'''\n",
    "    trans_G = nx.transitive_closure(G)\n",
    "    succesors_dict = {}\n",
    "    for node in trans_G.nodes():\n",
    "        succesors_dict[node] = list(G.predecessors(node))\n",
    "    return succesors_dict\n",
    "\n",
    "def get_edge_neighbor_max_min_avg_std(G):\n",
    "    '''For each edge, gets the maximum and minimum weight of its neighbors'''\n",
    "    edge_neighbor_max_min = {}\n",
    "    for edge in G.edges():\n",
    "        #gets the weights of the predecessors of the first node in the edge\n",
    "        pred_weights = [G.nodes[pred][\"weight\"] for pred in G.predecessors(edge[0])] \n",
    "        print(\"pred weights\", pred_weights)\n",
    "        #gets the weights of the successors of the second node in the edge\n",
    "        succ_weights = [G.nodes[succ][\"weight\"] for succ in G.successors(edge[1])] \n",
    "        print(\"succ weights\", succ_weights)\n",
    "        #adds the max and min of the weights to the edge_neighbor_max_min dictionary\n",
    "        weights = pred_weights + succ_weights\n",
    "        if weights:\n",
    "            edge_neighbor_max_min[edge] = {\"max\": max(weights), \"min\": min(weights), \"avg\": sum(weights)/len(weights), \"std\": np.std(weights)}\n",
    "        else:\n",
    "            edge_neighbor_max_min[edge] = {\"max\": 0, \"min\": 0, \"avg\": 0, \"std\": 0}\n",
    "    return edge_neighbor_max_min\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_edge_neighbor_max_min_avg_std(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_50.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets all of the instances where optimal is not equal to original optimal\n",
    "interesting_instances_50 = tasks_50[tasks_50[\"Upper bound on the number of stations\"] != tasks_50[\"original_optimal\"]]\n",
    "interesting_instances_50['instance:'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_instances_50.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_instances_50[['No of stations in optimum', 'original_optimal', 'Optimum found? -- 1 for \"Yes\"','Upper bound on the number of stations', 'bin_lb', \"lowest_cost\"]].tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_instances_50[interesting_instances_50['No of stations in optimum'].isin([12,13,34]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.x Kernel with pytorch geometric",
   "language": "python",
   "name": "pytorch_geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
